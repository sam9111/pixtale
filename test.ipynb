{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samyuktha/pixtale/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing img_6626.mov\n",
      "Extracting metadata from img_6626.mov\n",
      "img_6626.mov is a video file\n",
      "Processing .ds_store\n",
      "Extracting metadata from .ds_store\n",
      "Processing img_6423.mov\n",
      "Extracting metadata from img_6423.mov\n",
      "img_6423.mov is a video file\n",
      "Processing img_6488.jpeg\n",
      "Extracting metadata from img_6488.jpeg\n",
      "No GPS Data on  /Users/samyuktha/Downloads/Pixtale KL Photos/img_6488.jpeg\n",
      "Processing img_6700.mov\n",
      "Extracting metadata from img_6700.mov\n",
      "img_6700.mov is a video file\n",
      "Processing img_6588.jpeg\n",
      "Extracting metadata from img_6588.jpeg\n",
      "No GPS Data on  /Users/samyuktha/Downloads/Pixtale KL Photos/img_6588.jpeg\n"
     ]
    }
   ],
   "source": [
    "from preprocess import *\n",
    "\n",
    "mediaitems = extract_metadata(\"/Users/samyuktha/Downloads/Pixtale KL Photos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import json\n",
    "\n",
    "with open(\"mediaitems.json\", \"r\") as json_file:\n",
    "    mediaitems = json.load(json_file)\n",
    "\n",
    "\n",
    "mediaitems = generate_descriptions(dir_path, mediaitems)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mediaitems.sort(key=lambda item: item[\"datetime\"])\n",
    "\n",
    "mediaitems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from geminiai import *\n",
    "\n",
    "with open(\"mediaitems.json\", \"r\") as json_file:\n",
    "    mediaitems = json.load(json_file)\n",
    "\n",
    "\n",
    "narration_script = get_script(mediaitems)\n",
    "\n",
    "narration_script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from moviepy.editor import (\n",
    "    VideoFileClip,\n",
    "    ImageClip,\n",
    "    concatenate_videoclips,\n",
    "    TextClip,\n",
    "    CompositeVideoClip,\n",
    "    concatenate_audioclips,\n",
    "    AudioFileClip,\n",
    ")\n",
    "from moviepy.video.fx.resize import resize\n",
    "import os\n",
    "from moviepy.video import fx as vfx\n",
    "from moviepy.video.fx import speedx\n",
    "\n",
    "\n",
    "clips = []\n",
    "\n",
    "# Define a standard resolution\n",
    "standard_resolution = (1080, 1920)  # Width x Height\n",
    "\n",
    "\n",
    "os.makedirs(\"./audio\")\n",
    "\n",
    "audio_clips = []\n",
    "# Process each scene\n",
    "for i in range(len(narration_script[\"scenes\"])):\n",
    "    scene = narration_script[\"scenes\"][i]\n",
    "\n",
    "    text = scene[\"text\"]\n",
    "\n",
    "    filepath = os.path.join(dir_path, scene[\"media_source\"]).lower()\n",
    "\n",
    "    print(filepath)\n",
    "\n",
    "    if os.path.exists(filepath):\n",
    "\n",
    "        if not os.path.exists(\"./audio/\" + str(i) + \".mp3\"):\n",
    "\n",
    "            synthesize_text(text, \"./audio/\" + str(i))\n",
    "\n",
    "        audio_clip = AudioFileClip(\"./audio/\" + str(i) + \".mp3\")\n",
    "\n",
    "        duration = audio_clip.duration\n",
    "\n",
    "        if filepath.endswith((\".mp4\", \".mov\")):\n",
    "            clip = VideoFileClip(filepath)\n",
    "\n",
    "            if duration < clip.duration:\n",
    "\n",
    "                clip = clip.subclip(0, duration)\n",
    "                \n",
    "            clip=clip.resize(newsize=(standard_resolution[0], standard_resolution[1]))\n",
    "\n",
    "        else:\n",
    "            clip = ImageClip(filepath).set_duration(duration)\n",
    "\n",
    "        # txt_clip = (\n",
    "        #     TextClip(\n",
    "        #         scene[\"narration\"][\"text\"],\n",
    "        #         color=\"white\",\n",
    "        #         font=\"Arial\",\n",
    "        #         fontsize=50,\n",
    "        #         method=\"caption\",\n",
    "        #         stroke_width=2,\n",
    "        #     )\n",
    "        #     .set_position(\"bottom\")\n",
    "        #     .set_duration(float(duration))\n",
    "        # )\n",
    "        # clip = CompositeVideoClip([clip, txt_clip])\n",
    "        clips.append(clip)\n",
    "\n",
    "        audio_clips.append(audio_clip)\n",
    "\n",
    "\n",
    "# shutil.rmtree(\"./audio\")\n",
    "# Concatenate all clips\n",
    "final_clip = concatenate_videoclips(clips, method=\"compose\")\n",
    "\n",
    "final_audio_clip = concatenate_audioclips(audio_clips)\n",
    "\n",
    "final_audio_clip.write_audiofile(\"final_trip_audio.mp3\")\n",
    "\n",
    "if final_clip.duration != final_audio_clip.duration:\n",
    "\n",
    "    if final_clip.duration > final_audio_clip.duration:\n",
    "        # Speed up the video clip to match the audio clip's duration\n",
    "        speed_factor = final_clip.duration / final_audio_clip.duration\n",
    "        final_clip = final_clip.fx(vfx.speedx, speed_factor)\n",
    "    else:\n",
    "        # Speed up the audio clip to match the video clip's duration\n",
    "\n",
    "        speed_factor = final_audio_clip.duration / final_clip.duration\n",
    "        print(speed_factor)\n",
    "        cmd = (\n",
    "            'ffmpeg -y -i final_trip_audio.mp3 -filter:a \"atempo={}\" output.mp3'.format(\n",
    "                speed_factor\n",
    "            )\n",
    "        )\n",
    "\n",
    "        os.system(cmd)\n",
    "\n",
    "\n",
    "# Write the result to a file\n",
    "final_clip.write_videofile(\"final_trip_video.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = \"ffmpeg -y -i final_trip_video.mp4 -i output.mp3 -map 0:v:0 -map 1:a:0 -c:v copy -c:a aac combined_video.mp4\"\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'language_codes': 'en-AU', 'ssml_gender': 'FEMALE', 'name': 'en-AU-Neural2-A', 'voice': 'en-AU-Neural2-A-FEMALE'}, {'language_codes': 'en-AU', 'ssml_gender': 'MALE', 'name': 'en-AU-Neural2-B', 'voice': 'en-AU-Neural2-B-MALE'}, {'language_codes': 'en-AU', 'ssml_gender': 'FEMALE', 'name': 'en-AU-Neural2-C', 'voice': 'en-AU-Neural2-C-FEMALE'}, {'language_codes': 'en-AU', 'ssml_gender': 'MALE', 'name': 'en-AU-Neural2-D', 'voice': 'en-AU-Neural2-D-MALE'}, {'language_codes': 'en-AU', 'ssml_gender': 'FEMALE', 'name': 'en-AU-News-E', 'voice': 'en-AU-News-E-FEMALE'}, {'language_codes': 'en-AU', 'ssml_gender': 'FEMALE', 'name': 'en-AU-News-F', 'voice': 'en-AU-News-F-FEMALE'}, {'language_codes': 'en-AU', 'ssml_gender': 'MALE', 'name': 'en-AU-News-G', 'voice': 'en-AU-News-G-MALE'}, {'language_codes': 'en-AU', 'ssml_gender': 'MALE', 'name': 'en-AU-Polyglot-1', 'voice': 'en-AU-Polyglot-1-MALE'}, {'language_codes': 'en-AU', 'ssml_gender': 'FEMALE', 'name': 'en-AU-Standard-A', 'voice': 'en-AU-Standard-A-FEMALE'}, {'language_codes': 'en-AU', 'ssml_gender': 'MALE', 'name': 'en-AU-Standard-B', 'voice': 'en-AU-Standard-B-MALE'}, {'language_codes': 'en-AU', 'ssml_gender': 'FEMALE', 'name': 'en-AU-Standard-C', 'voice': 'en-AU-Standard-C-FEMALE'}, {'language_codes': 'en-AU', 'ssml_gender': 'MALE', 'name': 'en-AU-Standard-D', 'voice': 'en-AU-Standard-D-MALE'}, {'language_codes': 'en-AU', 'ssml_gender': 'FEMALE', 'name': 'en-AU-Wavenet-A', 'voice': 'en-AU-Wavenet-A-FEMALE'}, {'language_codes': 'en-AU', 'ssml_gender': 'MALE', 'name': 'en-AU-Wavenet-B', 'voice': 'en-AU-Wavenet-B-MALE'}, {'language_codes': 'en-AU', 'ssml_gender': 'FEMALE', 'name': 'en-AU-Wavenet-C', 'voice': 'en-AU-Wavenet-C-FEMALE'}, {'language_codes': 'en-AU', 'ssml_gender': 'MALE', 'name': 'en-AU-Wavenet-D', 'voice': 'en-AU-Wavenet-D-MALE'}, {'language_codes': 'en-GB', 'ssml_gender': 'FEMALE', 'name': 'en-GB-Neural2-A', 'voice': 'en-GB-Neural2-A-FEMALE'}, {'language_codes': 'en-GB', 'ssml_gender': 'MALE', 'name': 'en-GB-Neural2-B', 'voice': 'en-GB-Neural2-B-MALE'}, {'language_codes': 'en-GB', 'ssml_gender': 'FEMALE', 'name': 'en-GB-Neural2-C', 'voice': 'en-GB-Neural2-C-FEMALE'}, {'language_codes': 'en-GB', 'ssml_gender': 'MALE', 'name': 'en-GB-Neural2-D', 'voice': 'en-GB-Neural2-D-MALE'}, {'language_codes': 'en-GB', 'ssml_gender': 'FEMALE', 'name': 'en-GB-Neural2-F', 'voice': 'en-GB-Neural2-F-FEMALE'}, {'language_codes': 'en-GB', 'ssml_gender': 'FEMALE', 'name': 'en-GB-News-G', 'voice': 'en-GB-News-G-FEMALE'}, {'language_codes': 'en-GB', 'ssml_gender': 'FEMALE', 'name': 'en-GB-News-H', 'voice': 'en-GB-News-H-FEMALE'}, {'language_codes': 'en-GB', 'ssml_gender': 'FEMALE', 'name': 'en-GB-News-I', 'voice': 'en-GB-News-I-FEMALE'}, {'language_codes': 'en-GB', 'ssml_gender': 'MALE', 'name': 'en-GB-News-J', 'voice': 'en-GB-News-J-MALE'}, {'language_codes': 'en-GB', 'ssml_gender': 'MALE', 'name': 'en-GB-News-K', 'voice': 'en-GB-News-K-MALE'}, {'language_codes': 'en-GB', 'ssml_gender': 'MALE', 'name': 'en-GB-News-L', 'voice': 'en-GB-News-L-MALE'}, {'language_codes': 'en-GB', 'ssml_gender': 'MALE', 'name': 'en-GB-News-M', 'voice': 'en-GB-News-M-MALE'}, {'language_codes': 'en-GB', 'ssml_gender': 'FEMALE', 'name': 'en-GB-Standard-A', 'voice': 'en-GB-Standard-A-FEMALE'}, {'language_codes': 'en-GB', 'ssml_gender': 'MALE', 'name': 'en-GB-Standard-B', 'voice': 'en-GB-Standard-B-MALE'}, {'language_codes': 'en-GB', 'ssml_gender': 'FEMALE', 'name': 'en-GB-Standard-C', 'voice': 'en-GB-Standard-C-FEMALE'}, {'language_codes': 'en-GB', 'ssml_gender': 'MALE', 'name': 'en-GB-Standard-D', 'voice': 'en-GB-Standard-D-MALE'}, {'language_codes': 'en-GB', 'ssml_gender': 'FEMALE', 'name': 'en-GB-Standard-F', 'voice': 'en-GB-Standard-F-FEMALE'}, {'language_codes': 'en-GB', 'ssml_gender': 'MALE', 'name': 'en-GB-Studio-B', 'voice': 'en-GB-Studio-B-MALE'}, {'language_codes': 'en-GB', 'ssml_gender': 'FEMALE', 'name': 'en-GB-Studio-C', 'voice': 'en-GB-Studio-C-FEMALE'}, {'language_codes': 'en-GB', 'ssml_gender': 'FEMALE', 'name': 'en-GB-Wavenet-A', 'voice': 'en-GB-Wavenet-A-FEMALE'}, {'language_codes': 'en-GB', 'ssml_gender': 'MALE', 'name': 'en-GB-Wavenet-B', 'voice': 'en-GB-Wavenet-B-MALE'}, {'language_codes': 'en-GB', 'ssml_gender': 'FEMALE', 'name': 'en-GB-Wavenet-C', 'voice': 'en-GB-Wavenet-C-FEMALE'}, {'language_codes': 'en-GB', 'ssml_gender': 'MALE', 'name': 'en-GB-Wavenet-D', 'voice': 'en-GB-Wavenet-D-MALE'}, {'language_codes': 'en-GB', 'ssml_gender': 'FEMALE', 'name': 'en-GB-Wavenet-F', 'voice': 'en-GB-Wavenet-F-FEMALE'}, {'language_codes': 'en-IN', 'ssml_gender': 'FEMALE', 'name': 'en-IN-Neural2-A', 'voice': 'en-IN-Neural2-A-FEMALE'}, {'language_codes': 'en-IN', 'ssml_gender': 'MALE', 'name': 'en-IN-Neural2-B', 'voice': 'en-IN-Neural2-B-MALE'}, {'language_codes': 'en-IN', 'ssml_gender': 'MALE', 'name': 'en-IN-Neural2-C', 'voice': 'en-IN-Neural2-C-MALE'}, {'language_codes': 'en-IN', 'ssml_gender': 'FEMALE', 'name': 'en-IN-Neural2-D', 'voice': 'en-IN-Neural2-D-FEMALE'}, {'language_codes': 'en-IN', 'ssml_gender': 'FEMALE', 'name': 'en-IN-Standard-A', 'voice': 'en-IN-Standard-A-FEMALE'}, {'language_codes': 'en-IN', 'ssml_gender': 'MALE', 'name': 'en-IN-Standard-B', 'voice': 'en-IN-Standard-B-MALE'}, {'language_codes': 'en-IN', 'ssml_gender': 'MALE', 'name': 'en-IN-Standard-C', 'voice': 'en-IN-Standard-C-MALE'}, {'language_codes': 'en-IN', 'ssml_gender': 'FEMALE', 'name': 'en-IN-Standard-D', 'voice': 'en-IN-Standard-D-FEMALE'}, {'language_codes': 'en-IN', 'ssml_gender': 'FEMALE', 'name': 'en-IN-Wavenet-A', 'voice': 'en-IN-Wavenet-A-FEMALE'}, {'language_codes': 'en-IN', 'ssml_gender': 'MALE', 'name': 'en-IN-Wavenet-B', 'voice': 'en-IN-Wavenet-B-MALE'}, {'language_codes': 'en-IN', 'ssml_gender': 'MALE', 'name': 'en-IN-Wavenet-C', 'voice': 'en-IN-Wavenet-C-MALE'}, {'language_codes': 'en-IN', 'ssml_gender': 'FEMALE', 'name': 'en-IN-Wavenet-D', 'voice': 'en-IN-Wavenet-D-FEMALE'}, {'language_codes': 'en-US', 'ssml_gender': 'MALE', 'name': 'en-US-Casual-K', 'voice': 'en-US-Casual-K-MALE'}, {'language_codes': 'en-US', 'ssml_gender': 'MALE', 'name': 'en-US-Journey-D', 'voice': 'en-US-Journey-D-MALE'}, {'language_codes': 'en-US', 'ssml_gender': 'FEMALE', 'name': 'en-US-Journey-F', 'voice': 'en-US-Journey-F-FEMALE'}, {'language_codes': 'en-US', 'ssml_gender': 'MALE', 'name': 'en-US-Neural2-A', 'voice': 'en-US-Neural2-A-MALE'}, {'language_codes': 'en-US', 'ssml_gender': 'FEMALE', 'name': 'en-US-Neural2-C', 'voice': 'en-US-Neural2-C-FEMALE'}, {'language_codes': 'en-US', 'ssml_gender': 'MALE', 'name': 'en-US-Neural2-D', 'voice': 'en-US-Neural2-D-MALE'}, {'language_codes': 'en-US', 'ssml_gender': 'FEMALE', 'name': 'en-US-Neural2-E', 'voice': 'en-US-Neural2-E-FEMALE'}, {'language_codes': 'en-US', 'ssml_gender': 'FEMALE', 'name': 'en-US-Neural2-F', 'voice': 'en-US-Neural2-F-FEMALE'}, {'language_codes': 'en-US', 'ssml_gender': 'FEMALE', 'name': 'en-US-Neural2-G', 'voice': 'en-US-Neural2-G-FEMALE'}, {'language_codes': 'en-US', 'ssml_gender': 'FEMALE', 'name': 'en-US-Neural2-H', 'voice': 'en-US-Neural2-H-FEMALE'}, {'language_codes': 'en-US', 'ssml_gender': 'MALE', 'name': 'en-US-Neural2-I', 'voice': 'en-US-Neural2-I-MALE'}, {'language_codes': 'en-US', 'ssml_gender': 'MALE', 'name': 'en-US-Neural2-J', 'voice': 'en-US-Neural2-J-MALE'}, {'language_codes': 'en-US', 'ssml_gender': 'FEMALE', 'name': 'en-US-News-K', 'voice': 'en-US-News-K-FEMALE'}, {'language_codes': 'en-US', 'ssml_gender': 'FEMALE', 'name': 'en-US-News-L', 'voice': 'en-US-News-L-FEMALE'}, {'language_codes': 'en-US', 'ssml_gender': 'MALE', 'name': 'en-US-News-N', 'voice': 'en-US-News-N-MALE'}, {'language_codes': 'en-US', 'ssml_gender': 'MALE', 'name': 'en-US-Polyglot-1', 'voice': 'en-US-Polyglot-1-MALE'}, {'language_codes': 'en-US', 'ssml_gender': 'MALE', 'name': 'en-US-Standard-A', 'voice': 'en-US-Standard-A-MALE'}, {'language_codes': 'en-US', 'ssml_gender': 'MALE', 'name': 'en-US-Standard-B', 'voice': 'en-US-Standard-B-MALE'}, {'language_codes': 'en-US', 'ssml_gender': 'FEMALE', 'name': 'en-US-Standard-C', 'voice': 'en-US-Standard-C-FEMALE'}, {'language_codes': 'en-US', 'ssml_gender': 'MALE', 'name': 'en-US-Standard-D', 'voice': 'en-US-Standard-D-MALE'}, {'language_codes': 'en-US', 'ssml_gender': 'FEMALE', 'name': 'en-US-Standard-E', 'voice': 'en-US-Standard-E-FEMALE'}, {'language_codes': 'en-US', 'ssml_gender': 'FEMALE', 'name': 'en-US-Standard-F', 'voice': 'en-US-Standard-F-FEMALE'}, {'language_codes': 'en-US', 'ssml_gender': 'FEMALE', 'name': 'en-US-Standard-G', 'voice': 'en-US-Standard-G-FEMALE'}, {'language_codes': 'en-US', 'ssml_gender': 'FEMALE', 'name': 'en-US-Standard-H', 'voice': 'en-US-Standard-H-FEMALE'}, {'language_codes': 'en-US', 'ssml_gender': 'MALE', 'name': 'en-US-Standard-I', 'voice': 'en-US-Standard-I-MALE'}, {'language_codes': 'en-US', 'ssml_gender': 'MALE', 'name': 'en-US-Standard-J', 'voice': 'en-US-Standard-J-MALE'}, {'language_codes': 'en-US', 'ssml_gender': 'FEMALE', 'name': 'en-US-Studio-O', 'voice': 'en-US-Studio-O-FEMALE'}, {'language_codes': 'en-US', 'ssml_gender': 'MALE', 'name': 'en-US-Studio-Q', 'voice': 'en-US-Studio-Q-MALE'}, {'language_codes': 'en-US', 'ssml_gender': 'MALE', 'name': 'en-US-Wavenet-A', 'voice': 'en-US-Wavenet-A-MALE'}, {'language_codes': 'en-US', 'ssml_gender': 'MALE', 'name': 'en-US-Wavenet-B', 'voice': 'en-US-Wavenet-B-MALE'}, {'language_codes': 'en-US', 'ssml_gender': 'FEMALE', 'name': 'en-US-Wavenet-C', 'voice': 'en-US-Wavenet-C-FEMALE'}, {'language_codes': 'en-US', 'ssml_gender': 'MALE', 'name': 'en-US-Wavenet-D', 'voice': 'en-US-Wavenet-D-MALE'}, {'language_codes': 'en-US', 'ssml_gender': 'FEMALE', 'name': 'en-US-Wavenet-E', 'voice': 'en-US-Wavenet-E-FEMALE'}, {'language_codes': 'en-US', 'ssml_gender': 'FEMALE', 'name': 'en-US-Wavenet-F', 'voice': 'en-US-Wavenet-F-FEMALE'}, {'language_codes': 'en-US', 'ssml_gender': 'FEMALE', 'name': 'en-US-Wavenet-G', 'voice': 'en-US-Wavenet-G-FEMALE'}, {'language_codes': 'en-US', 'ssml_gender': 'FEMALE', 'name': 'en-US-Wavenet-H', 'voice': 'en-US-Wavenet-H-FEMALE'}, {'language_codes': 'en-US', 'ssml_gender': 'MALE', 'name': 'en-US-Wavenet-I', 'voice': 'en-US-Wavenet-I-MALE'}, {'language_codes': 'en-US', 'ssml_gender': 'MALE', 'name': 'en-US-Wavenet-J', 'voice': 'en-US-Wavenet-J-MALE'}]\n"
     ]
    }
   ],
   "source": [
    "def list_voices():\n",
    "    \"\"\"Lists the available voices.\"\"\"\n",
    "    from google.cloud import texttospeech\n",
    "\n",
    "    client = texttospeech.TextToSpeechClient()\n",
    "\n",
    "    # Performs the list voices request\n",
    "    voices = client.list_voices()\n",
    "\n",
    "    english_voices = []\n",
    "\n",
    "    for voice in voices.voices:\n",
    "\n",
    "        for language_code in voice.language_codes:\n",
    "            if \"en\" in language_code:\n",
    "\n",
    "                english_voices.append(\n",
    "                    {\n",
    "                        \"language_codes\": voice.language_codes[0],\n",
    "                        \"ssml_gender\": texttospeech.SsmlVoiceGender(\n",
    "                            voice.ssml_gender\n",
    "                        ).name,\n",
    "                        \"name\": voice.name,\n",
    "                        \"voice\": \"{}-{}\".format(\n",
    "                            voice.name,\n",
    "                            texttospeech.SsmlVoiceGender(voice.ssml_gender).name,\n",
    "                        ),\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    return english_voices\n",
    "\n",
    "print(list_voices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "public = \"./static/public\"\n",
    "with open(\"data/narration_script.json\", \"r\") as json_file:\n",
    "    narration_script = json.load(json_file)\n",
    "\n",
    "create_video(narration_script,public)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from utils import *\n",
    "\n",
    "\n",
    "with open(\"data/mediaitems.json\", \"r\") as file:\n",
    "    mediaitems = json.load(file)\n",
    "\n",
    "create_video(mediaitems, \"./static/public\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
